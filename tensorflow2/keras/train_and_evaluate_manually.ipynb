{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_toy_dataset(num_data):\n",
    "    X = np.random.randn(num_data, 3)\n",
    "    y = 3 * X[:, 0] - 2 * X[:, 1]**3 + 2 * X[:, 2]**2 + 0.5 * np.random.randn(num_data)\n",
    "    y = y[:, np.newaxis]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(10, activation=\"relu\", input_dim=3),\n",
    "        keras.layers.Dense(10, activation=\"relu\"),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 40000\n",
    "N_test = 4000\n",
    "\n",
    "num_epochs = 10\n",
    "learning_rate = 0.01\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get toy datasets\n",
    "X_train, y_train = make_toy_dataset(N_train)\n",
    "X_test, y_test = make_toy_dataset(N_test)\n",
    "\n",
    "# make datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=512).batch(batch_size)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "test_dataset = test_dataset.batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 1s 34us/sample - loss: 20.8785 - mae: 2.0121 - val_loss: 23.1281 - val_mae: 2.3853\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 1s 28us/sample - loss: 21.4569 - mae: 2.0702 - val_loss: 17.4709 - val_mae: 1.8779\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 1s 29us/sample - loss: 20.1491 - mae: 2.2558 - val_loss: 16.9986 - val_mae: 2.1039\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 1s 27us/sample - loss: 20.2106 - mae: 2.3894 - val_loss: 21.4594 - val_mae: 2.7616\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 1s 26us/sample - loss: 22.0698 - mae: 2.6033 - val_loss: 16.0861 - val_mae: 1.7284\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 1s 26us/sample - loss: 20.7067 - mae: 2.4448 - val_loss: 20.8101 - val_mae: 2.9489\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 1s 27us/sample - loss: 21.4307 - mae: 2.5867 - val_loss: 16.5107 - val_mae: 1.9710\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 1s 26us/sample - loss: 20.8718 - mae: 2.5351 - val_loss: 18.1345 - val_mae: 2.4604\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 1s 26us/sample - loss: 21.6338 - mae: 2.6326 - val_loss: 31.3347 - val_mae: 4.3543\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 1s 27us/sample - loss: 22.3206 - mae: 2.6665 - val_loss: 32.2011 - val_mae: 4.3780\n",
      "11.542363166809082 (sec)\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(optimizer, loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs, validation_data=(X_test, y_test))\n",
    "end = time.time()\n",
    "\n",
    "print(end - start, \"(sec)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss=19.388, val_loss=6.017464, mae=2.058, val_mae=1.298\n",
      "epoch 2: loss=14.959, val_loss=20.358269, mae=1.681, val_mae=2.008\n",
      "epoch 3: loss=21.478, val_loss=12.725346, mae=2.173, val_mae=1.874\n",
      "epoch 4: loss=16.453, val_loss=18.775377, mae=2.232, val_mae=1.906\n",
      "epoch 5: loss=18.049, val_loss=21.427860, mae=2.272, val_mae=1.969\n",
      "epoch 6: loss=24.390, val_loss=17.955822, mae=2.391, val_mae=1.749\n",
      "epoch 7: loss=15.706, val_loss=4.267157, mae=2.237, val_mae=1.111\n",
      "epoch 8: loss=9.485, val_loss=6.076662, mae=1.701, val_mae=1.599\n",
      "epoch 9: loss=8.370, val_loss=9.201537, mae=1.599, val_mae=2.159\n",
      "epoch 10: loss=9.432, val_loss=6.011655, mae=1.684, val_mae=1.645\n",
      "67.33499646186829 (sec)\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "loss_fn = keras.losses.MeanSquaredError()\n",
    "\n",
    "train_loss = keras.metrics.Mean()\n",
    "test_loss = keras.metrics.Mean()\n",
    "train_mae_metric = keras.metrics.MeanAbsoluteError()\n",
    "test_mae_metric = keras.metrics.MeanAbsoluteError()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    # train step \n",
    "    for x_batch, y_batch in train_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x_batch)\n",
    "            loss = loss_fn(y_batch, y_pred)\n",
    "        grads = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "        # accumulate metrics of one batch\n",
    "        train_loss(loss)\n",
    "        train_mae_metric(y_batch, y_pred)\n",
    "    \n",
    "    \n",
    "    # get metrics of one epoch and reset their states\n",
    "    train_loss_result = train_loss.result()\n",
    "    train_loss.reset_states()\n",
    "    \n",
    "    train_mae_result = train_mae_metric.result()\n",
    "    train_mae_metric.reset_states()\n",
    "    \n",
    "    \n",
    "    # evaluation step\n",
    "    for x_batch, y_batch in test_dataset:\n",
    "        y_pred = model(x_batch)\n",
    "        loss = loss_fn(y_batch, y_pred)\n",
    "        \n",
    "        # accumulate metrics\n",
    "        test_loss(loss)\n",
    "        test_mae_metric(y_batch, y_pred)\n",
    "    \n",
    "    \n",
    "    # get metrics and reset their states\n",
    "    test_loss_result = test_loss.result()\n",
    "    test_loss.reset_states()\n",
    "    \n",
    "    test_mae_result = test_mae_metric.result()\n",
    "    test_mae_metric.reset_states()\n",
    "    \n",
    "    \n",
    "    # print train logs\n",
    "    template = \"epoch {}: loss={:.3f}, val_loss={:3f}, mae={:.3f}, val_mae={:.3f}\"\n",
    "    print(template.format(epoch, train_loss_result, test_loss_result, train_mae_result, test_mae_result))\n",
    "\n",
    "end = time.time()\n",
    "print(end - start, \"(sec)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss=18.941, val_loss=7.673271, mae=2.099, val_mae=1.595\n",
      "epoch 2: loss=18.722, val_loss=13.874675, mae=2.145, val_mae=2.391\n",
      "epoch 3: loss=19.804, val_loss=26.229481, mae=2.227, val_mae=2.639\n",
      "epoch 4: loss=46.824, val_loss=72.437012, mae=3.544, val_mae=5.147\n",
      "epoch 5: loss=77.826, val_loss=72.400139, mae=5.236, val_mae=5.151\n",
      "epoch 6: loss=77.826, val_loss=72.400139, mae=5.236, val_mae=5.151\n",
      "epoch 7: loss=77.826, val_loss=72.400139, mae=5.236, val_mae=5.151\n",
      "epoch 8: loss=77.826, val_loss=72.400139, mae=5.236, val_mae=5.151\n",
      "epoch 9: loss=77.826, val_loss=72.400139, mae=5.236, val_mae=5.151\n",
      "epoch 10: loss=77.826, val_loss=72.400139, mae=5.236, val_mae=5.151\n",
      "24.06973624229431 (sec)\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "loss_fn = keras.losses.MeanSquaredError()\n",
    "\n",
    "train_loss = keras.metrics.Mean()\n",
    "test_loss = keras.metrics.Mean()\n",
    "train_mae_metric = keras.metrics.MeanAbsoluteError()\n",
    "test_mae_metric = keras.metrics.MeanAbsoluteError()\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    #print(\"tracing:\", model, optimizer, x, y)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y, y_pred)\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    return y_pred, loss\n",
    "\n",
    "@tf.function\n",
    "def eval_step(x, y):\n",
    "    #print(\"tracing:\", model, x, y)\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y, y_pred)\n",
    "    return y_pred, loss\n",
    "    \n",
    "start = time.time()\n",
    "    \n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    # train step \n",
    "    for x_batch, y_batch in train_dataset:\n",
    "        \n",
    "        y_pred, loss = train_step(x_batch, y_batch)\n",
    "        \n",
    "        # accumulate metrics of one batch\n",
    "        train_loss(loss)\n",
    "        train_mae_metric(y_batch, y_pred)\n",
    "    \n",
    "    \n",
    "    # get metrics of one epoch and reset their states\n",
    "    train_loss_result = train_loss.result()\n",
    "    train_loss.reset_states()\n",
    "    \n",
    "    train_mae_result = train_mae_metric.result()\n",
    "    train_mae_metric.reset_states()\n",
    "    \n",
    "    \n",
    "    # evaluation step\n",
    "    for x_batch, y_batch in test_dataset:\n",
    "        y_pred, loss = eval_step(x_batch, y_batch)\n",
    "        \n",
    "        # accumulate metrics\n",
    "        test_loss(loss)\n",
    "        test_mae_metric(y_batch, y_pred)\n",
    "    \n",
    "    \n",
    "    # get metrics and reset their states\n",
    "    test_loss_result = test_loss.result()\n",
    "    test_loss.reset_states()\n",
    "    \n",
    "    test_mae_result = test_mae_metric.result()\n",
    "    test_mae_metric.reset_states()\n",
    "    \n",
    "    \n",
    "    # print train logs\n",
    "    template = \"epoch {}: loss={:.3f}, val_loss={:3f}, mae={:.3f}, val_mae={:.3f}\"\n",
    "    print(template.format(epoch, train_loss_result, test_loss_result, train_mae_result, test_mae_result))\n",
    "    \n",
    "end = time.time()\n",
    "print(end - start, \"(sec)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss=22.800, val_loss=23.001825, mae=2.201, val_mae=2.252\n",
      "epoch 2: loss=23.168, val_loss=17.122089, mae=2.206, val_mae=1.905\n",
      "epoch 3: loss=21.588, val_loss=17.114124, mae=2.224, val_mae=1.894\n",
      "epoch 4: loss=19.981, val_loss=17.360416, mae=2.229, val_mae=2.223\n",
      "epoch 5: loss=20.611, val_loss=18.949278, mae=2.427, val_mae=2.594\n",
      "epoch 6: loss=21.235, val_loss=17.074144, mae=2.559, val_mae=2.316\n",
      "epoch 7: loss=21.006, val_loss=16.820246, mae=2.539, val_mae=2.287\n",
      "epoch 8: loss=21.351, val_loss=15.526962, mae=2.550, val_mae=1.986\n",
      "epoch 9: loss=21.109, val_loss=16.922367, mae=2.574, val_mae=2.299\n",
      "epoch 10: loss=21.178, val_loss=15.903707, mae=2.541, val_mae=2.035\n",
      "8.744144678115845 (sec)\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "loss_fn = keras.losses.MeanSquaredError()\n",
    "\n",
    "train_loss = keras.metrics.Mean()\n",
    "test_loss = keras.metrics.Mean()\n",
    "train_mae_metric = keras.metrics.MeanAbsoluteError()\n",
    "test_mae_metric = keras.metrics.MeanAbsoluteError()\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    #print(\"tracing:\", model, optimizer, x, y)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y, y_pred)\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    return y_pred, loss\n",
    "\n",
    "@tf.function\n",
    "def train_epoch(train_dataset):\n",
    "    for x_batch, y_batch in train_dataset:\n",
    "        \n",
    "        y_pred, loss = train_step(x_batch, y_batch)\n",
    "        \n",
    "        # accumulate metrics of one batch\n",
    "        train_loss(loss)\n",
    "        train_mae_metric(y_batch, y_pred)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def eval_step(x, y):\n",
    "    #print(\"tracing:\", model, x, y)\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y, y_pred)\n",
    "    return y_pred, loss\n",
    "    \n",
    "@tf.function\n",
    "def eval_epoch(test_dataset):\n",
    "    for x_batch, y_batch in test_dataset:\n",
    "        y_pred, loss = eval_step(x_batch, y_batch)\n",
    "        \n",
    "        # accumulate metrics\n",
    "        test_loss(loss)\n",
    "        test_mae_metric(y_batch, y_pred)\n",
    "\n",
    "    \n",
    "start = time.time()\n",
    "    \n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    # train step \n",
    "    train_epoch(train_dataset)\n",
    "    \n",
    "    # get metrics of one epoch and reset their states\n",
    "    train_loss_result = train_loss.result()\n",
    "    train_loss.reset_states()\n",
    "    \n",
    "    train_mae_result = train_mae_metric.result()\n",
    "    train_mae_metric.reset_states()\n",
    "    \n",
    "    \n",
    "    # evaluation step\n",
    "    eval_epoch(test_dataset)\n",
    "    \n",
    "    \n",
    "    # get metrics and reset their states\n",
    "    test_loss_result = test_loss.result()\n",
    "    test_loss.reset_states()\n",
    "    \n",
    "    test_mae_result = test_mae_metric.result()\n",
    "    test_mae_metric.reset_states()\n",
    "    \n",
    "    \n",
    "    # print train logs\n",
    "    template = \"epoch {}: loss={:.3f}, val_loss={:3f}, mae={:.3f}, val_mae={:.3f}\"\n",
    "    print(template.format(epoch, train_loss_result, test_loss_result, train_mae_result, test_mae_result))\n",
    "    \n",
    "end = time.time()\n",
    "print(end - start, \"(sec)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss=22.421, val_loss=22.303837, mae=2.165, val_mae=2.090\n",
      "epoch 2: loss=20.282, val_loss=13.559036, mae=1.821, val_mae=1.310\n",
      "epoch 3: loss=13.936, val_loss=10.135809, mae=1.358, val_mae=1.027\n",
      "epoch 4: loss=11.856, val_loss=20.876116, mae=1.396, val_mae=3.415\n",
      "epoch 5: loss=10.750, val_loss=21.758427, mae=1.409, val_mae=3.590\n",
      "epoch 6: loss=10.198, val_loss=18.974026, mae=1.455, val_mae=3.294\n",
      "epoch 7: loss=10.099, val_loss=18.623226, mae=1.532, val_mae=3.284\n",
      "epoch 8: loss=8.204, val_loss=10.179640, mae=1.250, val_mae=1.997\n",
      "epoch 9: loss=7.060, val_loss=9.346371, mae=1.064, val_mae=1.900\n",
      "epoch 10: loss=6.661, val_loss=8.727838, mae=1.043, val_mae=1.840\n",
      "7.924725532531738 (sec)\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "loss_fn = keras.losses.MeanSquaredError()\n",
    "\n",
    "train_loss = keras.metrics.Mean()\n",
    "test_loss = keras.metrics.Mean()\n",
    "train_mae_metric = keras.metrics.MeanAbsoluteError()\n",
    "test_mae_metric = keras.metrics.MeanAbsoluteError()\n",
    "\n",
    "\n",
    "def train_step(x, y):\n",
    "    #print(\"tracing:\", model, optimizer, x, y)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y, y_pred)\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    return y_pred, loss\n",
    "\n",
    "@tf.function\n",
    "def train_epoch(train_dataset):\n",
    "    for x_batch, y_batch in train_dataset:\n",
    "        \n",
    "        y_pred, loss = train_step(x_batch, y_batch)\n",
    "        \n",
    "        # accumulate metrics of one batch\n",
    "        train_loss(loss)\n",
    "        train_mae_metric(y_batch, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "def eval_step(x, y):\n",
    "    #print(\"tracing:\", model, x, y)\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y, y_pred)\n",
    "    return y_pred, loss\n",
    "    \n",
    "@tf.function\n",
    "def eval_epoch(test_dataset):\n",
    "    for x_batch, y_batch in test_dataset:\n",
    "        y_pred, loss = eval_step(x_batch, y_batch)\n",
    "        \n",
    "        # accumulate metrics\n",
    "        test_loss(loss)\n",
    "        test_mae_metric(y_batch, y_pred)\n",
    "\n",
    "    \n",
    "start = time.time()\n",
    "    \n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    # train step \n",
    "    train_epoch(train_dataset)\n",
    "    \n",
    "    # get metrics of one epoch and reset their states\n",
    "    train_loss_result = train_loss.result()\n",
    "    train_loss.reset_states()\n",
    "    \n",
    "    train_mae_result = train_mae_metric.result()\n",
    "    train_mae_metric.reset_states()\n",
    "    \n",
    "    \n",
    "    # evaluation step\n",
    "    eval_epoch(test_dataset)\n",
    "    \n",
    "    \n",
    "    # get metrics and reset their states\n",
    "    test_loss_result = test_loss.result()\n",
    "    test_loss.reset_states()\n",
    "    \n",
    "    test_mae_result = test_mae_metric.result()\n",
    "    test_mae_metric.reset_states()\n",
    "    \n",
    "    \n",
    "    # print train logs\n",
    "    template = \"epoch {}: loss={:.3f}, val_loss={:3f}, mae={:.3f}, val_mae={:.3f}\"\n",
    "    print(template.format(epoch, train_loss_result, test_loss_result, train_mae_result, test_mae_result))\n",
    "    \n",
    "end = time.time()\n",
    "print(end - start, \"(sec)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tf2)",
   "language": "python",
   "name": "py37tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
