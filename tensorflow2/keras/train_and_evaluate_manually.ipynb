{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_toy_dataset(num_data):\n",
    "    X = np.random.randn(num_data, 3)\n",
    "    y = 3 * X[:, 0] - 2 * X[:, 1]**3 + 2 * X[:, 2]**2 + 0.5 * np.random.randn(num_data)\n",
    "    y = y[:, np.newaxis]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(10, activation=\"relu\", input_dim=3),\n",
    "        keras.layers.Dense(10, activation=\"relu\"),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 20000\n",
    "N_test = 4000\n",
    "\n",
    "num_epochs = 15\n",
    "learning_rate = 0.01\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get toy datasets\n",
    "X_train, y_train = make_toy_dataset(N_train)\n",
    "X_test, y_test = make_toy_dataset(N_test)\n",
    "\n",
    "# make datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=512).batch(batch_size)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "test_dataset = test_dataset.batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss=17.115, val_loss=3.375274, mae=2.029, val_mae=0.992\n",
      "epoch 2: loss=5.456, val_loss=2.238686, mae=1.199, val_mae=0.890\n",
      "epoch 3: loss=3.136, val_loss=1.774873, mae=1.010, val_mae=0.835\n",
      "epoch 4: loss=2.144, val_loss=1.472416, mae=0.889, val_mae=0.779\n",
      "epoch 5: loss=1.624, val_loss=1.407722, mae=0.814, val_mae=0.759\n",
      "epoch 6: loss=1.381, val_loss=1.452342, mae=0.769, val_mae=0.781\n",
      "epoch 7: loss=1.240, val_loss=1.224803, mae=0.731, val_mae=0.720\n",
      "epoch 8: loss=1.143, val_loss=1.063762, mae=0.706, val_mae=0.674\n",
      "epoch 9: loss=1.081, val_loss=0.930714, mae=0.688, val_mae=0.635\n",
      "epoch 10: loss=1.053, val_loss=0.846581, mae=0.677, val_mae=0.612\n",
      "epoch 11: loss=0.994, val_loss=0.817619, mae=0.663, val_mae=0.603\n",
      "epoch 12: loss=0.983, val_loss=0.796920, mae=0.655, val_mae=0.585\n",
      "epoch 13: loss=0.943, val_loss=0.776129, mae=0.645, val_mae=0.580\n",
      "epoch 14: loss=0.909, val_loss=0.752312, mae=0.636, val_mae=0.573\n",
      "epoch 15: loss=0.871, val_loss=0.738428, mae=0.624, val_mae=0.571\n",
      "30.362996339797974 (sec)\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "loss_fn = keras.losses.MeanSquaredError()\n",
    "\n",
    "train_loss = keras.metrics.Mean()\n",
    "test_loss = keras.metrics.Mean()\n",
    "train_mae_metric = keras.metrics.MeanAbsoluteError()\n",
    "test_mae_metric = keras.metrics.MeanAbsoluteError()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    # train step \n",
    "    for x_batch, y_batch in train_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x_batch)\n",
    "            loss = loss_fn(y_batch, y_pred)\n",
    "        grads = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "        # accumulate metrics of one batch\n",
    "        train_loss(loss)\n",
    "        train_mae_metric(y_batch, y_pred)\n",
    "    \n",
    "    \n",
    "    # get metrics of one epoch and reset their states\n",
    "    train_loss_result = train_loss.result()\n",
    "    train_loss.reset_states()\n",
    "    \n",
    "    train_mae_result = train_mae_metric.result()\n",
    "    train_mae_metric.reset_states()\n",
    "    \n",
    "    \n",
    "    # evaluation step\n",
    "    for x_batch, y_batch in test_dataset:\n",
    "        y_pred = model(x_batch)\n",
    "        loss = loss_fn(y_batch, y_pred)\n",
    "        \n",
    "        # accumulate metrics\n",
    "        test_loss(loss)\n",
    "        test_mae_metric(y_batch, y_pred)\n",
    "    \n",
    "    \n",
    "    # get metrics and reset their states\n",
    "    test_loss_result = test_loss.result()\n",
    "    test_loss.reset_states()\n",
    "    \n",
    "    test_mae_result = test_mae_metric.result()\n",
    "    test_mae_metric.reset_states()\n",
    "    \n",
    "    \n",
    "    # print train logs\n",
    "    template = \"epoch {}: loss={:.3f}, val_loss={:3f}, mae={:.3f}, val_mae={:.3f}\"\n",
    "    print(template.format(epoch, train_loss_result, test_loss_result, train_mae_result, test_mae_result))\n",
    "\n",
    "end = time.time()\n",
    "print(end - start, \"(sec)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss=17.350, val_loss=3.608866, mae=2.032, val_mae=1.004\n",
      "epoch 2: loss=6.333, val_loss=2.454494, mae=1.211, val_mae=0.910\n",
      "epoch 3: loss=3.939, val_loss=1.827998, mae=1.040, val_mae=0.828\n",
      "epoch 4: loss=2.751, val_loss=1.508731, mae=0.934, val_mae=0.760\n",
      "epoch 5: loss=2.305, val_loss=1.303485, mae=0.877, val_mae=0.724\n",
      "epoch 6: loss=1.914, val_loss=1.155705, mae=0.821, val_mae=0.692\n",
      "epoch 7: loss=1.659, val_loss=1.033534, mae=0.777, val_mae=0.664\n",
      "epoch 8: loss=1.436, val_loss=0.947385, mae=0.738, val_mae=0.638\n",
      "epoch 9: loss=1.278, val_loss=0.895112, mae=0.708, val_mae=0.618\n",
      "epoch 10: loss=1.189, val_loss=0.884551, mae=0.689, val_mae=0.615\n",
      "epoch 11: loss=1.072, val_loss=0.869028, mae=0.668, val_mae=0.609\n",
      "epoch 12: loss=0.985, val_loss=0.864501, mae=0.651, val_mae=0.606\n",
      "epoch 13: loss=0.931, val_loss=0.835071, mae=0.637, val_mae=0.596\n",
      "epoch 14: loss=0.895, val_loss=0.804948, mae=0.628, val_mae=0.584\n",
      "epoch 15: loss=0.867, val_loss=0.776026, mae=0.620, val_mae=0.574\n",
      "12.359346628189087 (sec)\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "loss_fn = keras.losses.MeanSquaredError()\n",
    "\n",
    "train_loss = keras.metrics.Mean()\n",
    "test_loss = keras.metrics.Mean()\n",
    "train_mae_metric = keras.metrics.MeanAbsoluteError()\n",
    "test_mae_metric = keras.metrics.MeanAbsoluteError()\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    #print(\"tracing:\", model, optimizer, x, y)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y, y_pred)\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    return y_pred, loss\n",
    "\n",
    "@tf.function\n",
    "def eval_step(x, y):\n",
    "    #print(\"tracing:\", model, x, y)\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y, y_pred)\n",
    "    return y_pred, loss\n",
    "    \n",
    "start = time.time()\n",
    "    \n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    # train step \n",
    "    for x_batch, y_batch in train_dataset:\n",
    "        \n",
    "        y_pred, loss = train_step(x_batch, y_batch)\n",
    "        \n",
    "        # accumulate metrics of one batch\n",
    "        train_loss(loss)\n",
    "        train_mae_metric(y_batch, y_pred)\n",
    "    \n",
    "    \n",
    "    # get metrics of one epoch and reset their states\n",
    "    train_loss_result = train_loss.result()\n",
    "    train_loss.reset_states()\n",
    "    \n",
    "    train_mae_result = train_mae_metric.result()\n",
    "    train_mae_metric.reset_states()\n",
    "    \n",
    "    \n",
    "    # evaluation step\n",
    "    for x_batch, y_batch in test_dataset:\n",
    "        y_pred, loss = eval_step(x_batch, y_batch)\n",
    "        \n",
    "        # accumulate metrics\n",
    "        test_loss(loss)\n",
    "        test_mae_metric(y_batch, y_pred)\n",
    "    \n",
    "    \n",
    "    # get metrics and reset their states\n",
    "    test_loss_result = test_loss.result()\n",
    "    test_loss.reset_states()\n",
    "    \n",
    "    test_mae_result = test_mae_metric.result()\n",
    "    test_mae_metric.reset_states()\n",
    "    \n",
    "    \n",
    "    # print train logs\n",
    "    template = \"epoch {}: loss={:.3f}, val_loss={:3f}, mae={:.3f}, val_mae={:.3f}\"\n",
    "    print(template.format(epoch, train_loss_result, test_loss_result, train_mae_result, test_mae_result))\n",
    "    \n",
    "end = time.time()\n",
    "print(end - start, \"(sec)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss=17.949, val_loss=3.986042, mae=2.112, val_mae=1.071\n",
      "epoch 2: loss=6.944, val_loss=3.429074, mae=1.286, val_mae=1.090\n",
      "epoch 3: loss=5.643, val_loss=2.928119, mae=1.193, val_mae=1.055\n",
      "epoch 4: loss=2.933, val_loss=1.601469, mae=0.950, val_mae=0.787\n",
      "epoch 5: loss=2.298, val_loss=1.300984, mae=0.861, val_mae=0.732\n",
      "epoch 6: loss=1.907, val_loss=1.136901, mae=0.818, val_mae=0.723\n",
      "epoch 7: loss=1.615, val_loss=1.193632, mae=0.789, val_mae=0.745\n",
      "epoch 8: loss=1.486, val_loss=1.134603, mae=0.768, val_mae=0.730\n",
      "epoch 9: loss=1.401, val_loss=1.108949, mae=0.754, val_mae=0.727\n",
      "epoch 10: loss=1.339, val_loss=1.061932, mae=0.739, val_mae=0.714\n",
      "epoch 11: loss=1.299, val_loss=1.020469, mae=0.730, val_mae=0.704\n",
      "epoch 12: loss=1.257, val_loss=0.975169, mae=0.717, val_mae=0.692\n",
      "epoch 13: loss=1.188, val_loss=0.946663, mae=0.706, val_mae=0.687\n",
      "epoch 14: loss=1.149, val_loss=0.896120, mae=0.698, val_mae=0.670\n",
      "epoch 15: loss=1.107, val_loss=0.871174, mae=0.688, val_mae=0.659\n",
      "5.655078649520874 (sec)\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "loss_fn = keras.losses.MeanSquaredError()\n",
    "\n",
    "train_loss = keras.metrics.Mean()\n",
    "test_loss = keras.metrics.Mean()\n",
    "train_mae_metric = keras.metrics.MeanAbsoluteError()\n",
    "test_mae_metric = keras.metrics.MeanAbsoluteError()\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    #print(\"tracing:\", model, optimizer, x, y)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y, y_pred)\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    return y_pred, loss\n",
    "\n",
    "@tf.function\n",
    "def train_epoch(train_dataset):\n",
    "    for x_batch, y_batch in train_dataset:\n",
    "        \n",
    "        y_pred, loss = train_step(x_batch, y_batch)\n",
    "        \n",
    "        # accumulate metrics of one batch\n",
    "        train_loss(loss)\n",
    "        train_mae_metric(y_batch, y_pred)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def eval_step(x, y):\n",
    "    #print(\"tracing:\", model, x, y)\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y, y_pred)\n",
    "    return y_pred, loss\n",
    "    \n",
    "@tf.function\n",
    "def eval_epoch(test_dataset):\n",
    "    for x_batch, y_batch in test_dataset:\n",
    "        y_pred, loss = eval_step(x_batch, y_batch)\n",
    "        \n",
    "        # accumulate metrics\n",
    "        test_loss(loss)\n",
    "        test_mae_metric(y_batch, y_pred)\n",
    "\n",
    "    \n",
    "start = time.time()\n",
    "    \n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    # train step \n",
    "    train_epoch(train_dataset)\n",
    "    \n",
    "    # get metrics of one epoch and reset their states\n",
    "    train_loss_result = train_loss.result()\n",
    "    train_loss.reset_states()\n",
    "    \n",
    "    train_mae_result = train_mae_metric.result()\n",
    "    train_mae_metric.reset_states()\n",
    "    \n",
    "    \n",
    "    # evaluation step\n",
    "    eval_epoch(test_dataset)\n",
    "    \n",
    "    \n",
    "    # get metrics and reset their states\n",
    "    test_loss_result = test_loss.result()\n",
    "    test_loss.reset_states()\n",
    "    \n",
    "    test_mae_result = test_mae_metric.result()\n",
    "    test_mae_metric.reset_states()\n",
    "    \n",
    "    \n",
    "    # print train logs\n",
    "    template = \"epoch {}: loss={:.3f}, val_loss={:3f}, mae={:.3f}, val_mae={:.3f}\"\n",
    "    print(template.format(epoch, train_loss_result, test_loss_result, train_mae_result, test_mae_result))\n",
    "    \n",
    "end = time.time()\n",
    "print(end - start, \"(sec)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tf2)",
   "language": "python",
   "name": "py37tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
